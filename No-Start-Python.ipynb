{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03957692-2b44-4c83-8e70-ce7e79d5d17e",
   "metadata": {},
   "source": [
    "![pAIthon Labs Logo](https://raw.githubusercontent.com/worldfamous718/Labs/Logos-Files/pAIthonLogo.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c86e2f0-2fcb-438a-af4a-b698fcc6c921",
   "metadata": {},
   "source": [
    "# Conclusion of CSC 221\n",
    "\n",
    "## Reflection on Learning Progress\n",
    "\n",
    "I am more than happy with what I have learned and the mindset for coding that I have developed. This project tested every bit of my patience, but my determination was the overall winner.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "For this project, I combined my basic knowledge of Python to develop a spoof. This spoof may just trick you into thinking the book you are buying is really something it isn't.\n",
    "\n",
    "## Technical Details\n",
    "\n",
    "- Used a variety of different libraries and modules\n",
    "- Demonstrated the versatility of Python as a programming language\n",
    "- Learned new concepts and techniques along the way\n",
    "\n",
    "## Challenges Encountered\n",
    "\n",
    "Welcome to the life of a developer!\n",
    "\n",
    "Some previously known methods weren't working as expected. This led to further learning and problem-solving.\n",
    "\n",
    "## Project Status\n",
    "\n",
    "While it's not perfect yet, I'm proud of what I was able to figure out and make work. There's still room for improvement, and I still have some time to continue refining it.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "I'll continue working on optimizing and enhancing the project over the next 2 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fccb5514-5f98-4535-82c2-1a80ae9c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# World..redacted\n",
    "# CSC 221 Final Project\n",
    "# Web Scraping and Data Visualization\n",
    "# 11/21/2024\n",
    "\n",
    "# IMPORT LIBRARIES AND MODULES FOR MY PROJECT:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23ca3da7-b357-414c-be1b-6fa38aa3277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TIME DELAY BETWEEN FET REQUESTS TO AVOID ERRORS:\n",
    "\n",
    "time.sleep(2)  # Wait for 2 seconds between requests\n",
    "\n",
    "# THIS IS THE SITE I WILL BE SCRAPING\n",
    "BASE_URL = \"https://nostarch.com/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "86dcf8b6-2dc7-4753-94e5-ec6105dac878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD WEB SCRAPER:\n",
    "\n",
    "def scrape_book_page(url):\n",
    "    full_url = f\"{BASE_URL}/{url}\"\n",
    "    response = requests.get(full_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    books = []\n",
    "\n",
    "    # I'M USING A REGULAR EXPRESSION HERE SO I CAN BROADEN MY SEARCH. IT WAS HARD TO FIND WHAT I WAS LOOKING FOR:\n",
    "    \n",
    "    book_elements = soup.find_all(['article', 'div'], class_=re.compile(r'node|product|teaser|clearfix'))\n",
    "\n",
    "    for element in book_elements:\n",
    "        h2_element = element.find('h2')\n",
    "        if h2_element and h2_element.a:\n",
    "            title = h2_element.a.text.strip()\n",
    "            url = BASE_URL + h2_element.a['href']\n",
    "\n",
    "            author_element = element.find('div', class_=re.compile(r'field-name-field-author|author'))\n",
    "            if author_element:\n",
    "                author_text = author_element.find('div', class_='field-items').find('div', class_='field-item even')\n",
    "                if author_text and author_text.text.strip():\n",
    "                    author = author_text.text.strip()\n",
    "\n",
    "            # ADD ITEMS TO MY BOOK LIST:\n",
    "            \n",
    "            books.append({\n",
    "                'Title': title,\n",
    "                'URL': url,\n",
    "                'Author': author if author else '',\n",
    "                'Number of Pages': '',\n",
    "                'Release Date': ''\n",
    "            })\n",
    "\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "97227f47-7183-4d18-b6f2-1021634fe8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WHY I WILL BE A DEVELOPER. ITS MY WORK AROUND FUNCTION TO FORCE ELEMENTS THAT I COULDNT GET TO SCRAPE\n",
    "# I AM USING RANDOM TO GENERATE INFO REGARDLESS IF THE SCRAPER MISSES SOMETHING. IT WAS MISSING PAGE  NUMBERS AND DATES:\n",
    "\n",
    "def scrape_book_details(books):\n",
    "    start_date = datetime(1999, 4, 1)\n",
    "    end_date = datetime(2024, 7, 2)\n",
    "\n",
    "    for book in books:\n",
    "        num_pages = str(random.randint(216, 855))\n",
    "        random_date = start_date + timedelta(\n",
    "            seconds=random.randint(0, int((end_date - start_date).total_seconds())),\n",
    "        )\n",
    "        release_date = random_date.strftime('%B %Y')\n",
    "\n",
    "        book['Number of Pages'] = f\"{num_pages} pp.\"\n",
    "        book['Release Date'] = release_date\n",
    "\n",
    "    return books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e3edd73f-de58-439a-94ef-9f84aa645159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS HOW IM FORMATTING MY CSV FILE OUTPUT WITH ALL THE COLUMS I SCRAPED:\n",
    "\n",
    "def save_to_csv(books):\n",
    "    fieldnames = ['Title', 'Author', 'Number of Pages', 'Release Date', 'URL']\n",
    "    with open('python_books.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for index, book in enumerate(books, 1):\n",
    "            writer.writerow({\n",
    "                'Title': book.get('Title'),\n",
    "                'Author': book.get('Author', ''),\n",
    "                'Number of Pages': book.get('Number of Pages', '').strip(),\n",
    "                'Release Date': book.get('Release Date', '').strip(),\n",
    "                'URL': book.get('URL')\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7f4afa9a-6078-4380-9aba-367d81e5365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDAS DIDNT LIKE MY CUSTOM WORKAROUND SO IT WAS GIVING ME ISSUES, THIS IS THE BEST I CAN COME UP WITH FOR OUTPUT:\n",
    "\n",
    "def display_first_10_results(books):\n",
    "    for index, book in enumerate(books[:10], 1):\n",
    "        print(f\"\\nBook {index}:\")\n",
    "        print(f\"Title: {book.get('Title', '')}\")\n",
    "        print(f\"Author: {book.get('Author', 'N')}\")\n",
    "        print(f\"Number of Pages: {book.get('Number of Pages', '')}\")\n",
    "        print(f\"Release Date: {book.get('Release Date', '')}\")\n",
    "        print(f\"URL: {book.get('URL')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "923434ea-2cb1-4ca7-b3a8-878a708990f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Your spoofed .csv is ready!\n",
      "Here is a sample of your first 10 results:\n",
      "\n",
      "Book 1:\n",
      "Title: Python for Excel Power Users\n",
      "Author: Tracy Stephens\n",
      "Number of Pages: 558 pp.\n",
      "Release Date: September 2009\n",
      "URL: https://nostarch.com//python-excel\n",
      "\n",
      "Book 2:\n",
      "Title: Automate the Boring Stuff with Python, 3rd Edition\n",
      "Author: Al Sweigart\n",
      "Number of Pages: 233 pp.\n",
      "Release Date: January 2022\n",
      "URL: https://nostarch.com//automate-boring-stuff-python-3rd-edition\n",
      "\n",
      "Book 3:\n",
      "Title: Python Playground, 2nd Edition\n",
      "Author: Mahesh Venkitachalam\n",
      "Number of Pages: 411 pp.\n",
      "Release Date: August 2013\n",
      "URL: https://nostarch.com//python-playground-2nd-edition\n",
      "\n",
      "Book 4:\n",
      "Title: Python for Kids, 2nd Edition\n",
      "Author: Jason R. Briggs\n",
      "Number of Pages: 692 pp.\n",
      "Release Date: July 2017\n",
      "URL: https://nostarch.com//python-kids-2nd-edition\n",
      "\n",
      "Book 5:\n",
      "Title: Dive Into Data Science\n",
      "Author: Bradford Tuckfield\n",
      "Number of Pages: 226 pp.\n",
      "Release Date: October 2022\n",
      "URL: https://nostarch.com//dive-data-science\n",
      "\n",
      "Book 6:\n",
      "Title: Python Crash Course, 3rd Edition\n",
      "Author: Eric Matthes\n",
      "Number of Pages: 536 pp.\n",
      "Release Date: December 2004\n",
      "URL: https://nostarch.com//python-crash-course-3rd-edition\n",
      "\n",
      "Book 7:\n",
      "Title: Python Tools for Scientists\n",
      "Author: Lee Vaughan\n",
      "Number of Pages: 428 pp.\n",
      "Release Date: April 2005\n",
      "URL: https://nostarch.com//python-tools-scientists\n",
      "\n",
      "Book 8:\n",
      "Title: Python for Data Science\n",
      "Author: Yuli Vasiliev\n",
      "Number of Pages: 725 pp.\n",
      "Release Date: January 2013\n",
      "URL: https://nostarch.com//python-data-science\n",
      "\n",
      "Book 9:\n",
      "Title: The Art of Clean Code\n",
      "Author: Christian Mayer\n",
      "Number of Pages: 698 pp.\n",
      "Release Date: January 2016\n",
      "URL: https://nostarch.com//art-clean-code\n",
      "\n",
      "Book 10:\n",
      "Title: The Book of Dash\n",
      "Author: Adam Schroeder, Christian Mayer, and Ann Marie Ward\n",
      "Number of Pages: 722 pp.\n",
      "Release Date: September 2019\n",
      "URL: https://nostarch.com//book-dash\n"
     ]
    }
   ],
   "source": [
    "# THIS IS HOW SOMEONE WHO SAYS THEY WANT TO BE A DEVELOPER DEFINES A PROPER MAIN FUNCTION\n",
    "# AND TO THINK IN CSC 121 I DIDNT EVEN UNDERSTAND THE PURPOSE OF MAIN, LOL:\n",
    "\n",
    "def main():\n",
    "    url = \"catalog/python\"\n",
    "    books = scrape_book_page(url)\n",
    "    books = scrape_book_details(books)\n",
    "\n",
    "    save_to_csv(books)\n",
    "\n",
    "    print(\"Scraping complete! Your spoofed .csv is ready!\")\n",
    "    print('Here is a sample of your first 10 results:')\n",
    "    # Print only the first 10 results\n",
    "    #print(\"\\nFirst 10 Results:\")\n",
    "    display_first_10_results(books)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c42207c-3115-468e-831c-9c1dde9436b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
