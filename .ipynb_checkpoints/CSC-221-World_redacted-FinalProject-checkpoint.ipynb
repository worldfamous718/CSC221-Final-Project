{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c371e5a-77e0-4247-b696-03c0ae720bb9",
   "metadata": {},
   "source": [
    "![pAIthon Labs Logo](https://raw.githubusercontent.com/worldfamous718/pAIthon-Labs/main/Labs/Logos-Files/Lab-Logo.png)\n",
    "\n",
    "# Conclusion of CSC 221\n",
    "\n",
    "## Reflection on Learning Progress\n",
    "\n",
    "I am more than happy with what I have learned and the mindset for coding that I have developed. This project tested every bit of my patience, but my determination was the overall winner.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "For this project, I combined my basic knowledge of Python to develop a spoof. This spoof may just trick you into thinking the book you are buying is really something it isn't.\n",
    "\n",
    "## Technical Details\n",
    "\n",
    "- Used a variety of different libraries and modules\n",
    "- Demonstrated the versatility of Python as a programming language\n",
    "- Learned new concepts and techniques along the way\n",
    "\n",
    "## Challenges Encountered\n",
    "\n",
    "Welcome to the life of a developer!\n",
    "\n",
    "Some previously known methods weren't working as expected. This led to further learning and problem-solving.\n",
    "\n",
    "## Project Status\n",
    "\n",
    "While it's not perfect yet, I'm proud of what I was able to figure out and make work. There's still room for improvement, and I still have some time to continue refining it.\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "I'll continue working on optimizing and enhancing the project over the next 2 weeks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fccb5514-5f98-4535-82c2-1a80ae9c2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# World..redacted\n",
    "# CSC 221 Final Project\n",
    "# Web Scraping and Data Visualization\n",
    "# 11/21/2024\n",
    "\n",
    "# IMPORT LIBRARIES AND MODULES FOR MY PROJECT:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime, timedelta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23ca3da7-b357-414c-be1b-6fa38aa3277d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TIME DELAY BETWEEN FET REQUESTS TO AVOID ERRORS:\n",
    "\n",
    "time.sleep(2)  # Wait for 2 seconds between requests\n",
    "\n",
    "# THIS IS THE SITE I WILL BE SCRAPING\n",
    "BASE_URL = \"https://nostarch.com/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0883d67f-1514-410b-9a82-84dde9f09610",
   "metadata": {},
   "source": [
    "# Building Our Web Scraper\n",
    "\n",
    "Before we dive into the code, let's take a moment to appreciate the power of web scraping!\n",
    "\n",
    "\n",
    "![Web Scraping](BSoup.jpg)\n",
    "\n",
    "In this project, we're going to build a web scraper to extract information about Python books from the No Starch Press website. We'll use the BeautifulSoup library to parse the HTML content and extract the relevant data.\n",
    "\n",
    "Our scraper will:\n",
    "- Scrape book titles, authors, and URLs\n",
    "- Generate fictional page counts and publication dates where real data isn't available\n",
    "- Save the extracted information to a CSV file\n",
    "- Display the first 10 results in the console\n",
    "\n",
    "This project showcases several key aspects of web scraping:\n",
    "- Using HTTP requests to fetch webpage content\n",
    "- Parsing HTML with BeautifulSoup\n",
    "- Handling dynamic content and missing data\n",
    "- Structuring and saving extracted information\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86dcf8b6-2dc7-4753-94e5-ec6105dac878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILD WEB SCRAPER:\n",
    "\n",
    "def scrape_book_page(url):\n",
    "    full_url = f\"{BASE_URL}/{url}\"\n",
    "    response = requests.get(full_url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    books = []\n",
    "\n",
    "    # I'M USING A REGULAR EXPRESSION HERE SO I CAN BROADEN MY SEARCH. IT WAS HARD TO FIND WHAT I WAS LOOKING FOR:\n",
    "    \n",
    "    book_elements = soup.find_all(['article', 'div'], class_=re.compile(r'node|product|teaser|clearfix'))\n",
    "\n",
    "    for element in book_elements:\n",
    "        h2_element = element.find('h2')\n",
    "        if h2_element and h2_element.a:\n",
    "            title = h2_element.a.text.strip()\n",
    "            url = BASE_URL + h2_element.a['href']\n",
    "\n",
    "            author_element = element.find('div', class_=re.compile(r'field-name-field-author|author'))\n",
    "            if author_element:\n",
    "                author_text = author_element.find('div', class_='field-items').find('div', class_='field-item even')\n",
    "                if author_text and author_text.text.strip():\n",
    "                    author = author_text.text.strip()\n",
    "\n",
    "            # ADD ITEMS TO MY BOOK LIST:\n",
    "            \n",
    "            books.append({\n",
    "                'Title': title,\n",
    "                'URL': url,\n",
    "                'Author': author if author else '',\n",
    "                'Number of Pages': '',\n",
    "                'Release Date': ''\n",
    "            })\n",
    "\n",
    "    return books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97227f47-7183-4d18-b6f2-1021634fe8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WHY I WILL BE A DEVELOPER. ITS MY WORK AROUND FUNCTION TO FORCE ELEMENTS THAT I COULDNT GET TO SCRAPE\n",
    "# I AM USING RANDOM TO GENERATE INFO REGARDLESS IF THE SCRAPER MISSES SOMETHING. IT WAS MISSING PAGE  NUMBERS AND DATES:\n",
    "\n",
    "def scrape_book_details(books):\n",
    "    start_date = datetime(1999, 4, 1)\n",
    "    end_date = datetime(2024, 7, 2)\n",
    "\n",
    "    for book in books:\n",
    "        num_pages = str(random.randint(216, 855))\n",
    "        random_date = start_date + timedelta(\n",
    "            seconds=random.randint(0, int((end_date - start_date).total_seconds())),\n",
    "        )\n",
    "        release_date = random_date.strftime('%B %Y')\n",
    "\n",
    "        book['Number of Pages'] = f\"{num_pages} pp.\"\n",
    "        book['Release Date'] = release_date\n",
    "\n",
    "    return books\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3edd73f-de58-439a-94ef-9f84aa645159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS HOW IM FORMATTING MY CSV FILE OUTPUT WITH ALL THE COLUMS I SCRAPED:\n",
    "\n",
    "def save_to_csv(books):\n",
    "    fieldnames = ['Title', 'Author', 'Number of Pages', 'Release Date', 'URL']\n",
    "    with open('python_books.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for index, book in enumerate(books, 1):\n",
    "            writer.writerow({\n",
    "                'Title': book.get('Title'),\n",
    "                'Author': book.get('Author', ''),\n",
    "                'Number of Pages': book.get('Number of Pages', '').strip(),\n",
    "                'Release Date': book.get('Release Date', '').strip(),\n",
    "                'URL': book.get('URL')\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4afa9a-6078-4380-9aba-367d81e5365c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PANDAS DIDNT LIKE MY CUSTOM WORKAROUND SO IT WAS GIVING ME ISSUES, THIS IS THE BEST I CAN COME UP WITH FOR OUTPUT:\n",
    "\n",
    "def display_first_10_results(books):\n",
    "    for index, book in enumerate(books[:10], 1):\n",
    "        print(f\"\\nBook {index}:\")\n",
    "        print(f\"Title: {book.get('Title', '')}\")\n",
    "        print(f\"Author: {book.get('Author', 'N')}\")\n",
    "        print(f\"Number of Pages: {book.get('Number of Pages', '')}\")\n",
    "        print(f\"Release Date: {book.get('Release Date', '')}\")\n",
    "        print(f\"URL: {book.get('URL')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "923434ea-2cb1-4ca7-b3a8-878a708990f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping complete! Your spoofed .csv is ready!\n",
      "Here is a sample of your first 10 results:\n",
      "\n",
      "Book 1:\n",
      "Title: Python for Excel Power Users\n",
      "Author: Tracy Stephens\n",
      "Number of Pages: 820 pp.\n",
      "Release Date: April 2004\n",
      "URL: https://nostarch.com//python-excel\n",
      "\n",
      "Book 2:\n",
      "Title: Automate the Boring Stuff with Python, 3rd Edition\n",
      "Author: Al Sweigart\n",
      "Number of Pages: 382 pp.\n",
      "Release Date: August 2000\n",
      "URL: https://nostarch.com//automate-boring-stuff-python-3rd-edition\n",
      "\n",
      "Book 3:\n",
      "Title: Python Playground, 2nd Edition\n",
      "Author: Mahesh Venkitachalam\n",
      "Number of Pages: 729 pp.\n",
      "Release Date: October 2000\n",
      "URL: https://nostarch.com//python-playground-2nd-edition\n",
      "\n",
      "Book 4:\n",
      "Title: Python for Kids, 2nd Edition\n",
      "Author: Jason R. Briggs\n",
      "Number of Pages: 291 pp.\n",
      "Release Date: June 2008\n",
      "URL: https://nostarch.com//python-kids-2nd-edition\n",
      "\n",
      "Book 5:\n",
      "Title: Dive Into Data Science\n",
      "Author: Bradford Tuckfield\n",
      "Number of Pages: 637 pp.\n",
      "Release Date: June 2018\n",
      "URL: https://nostarch.com//dive-data-science\n",
      "\n",
      "Book 6:\n",
      "Title: Python Crash Course, 3rd Edition\n",
      "Author: Eric Matthes\n",
      "Number of Pages: 648 pp.\n",
      "Release Date: September 2012\n",
      "URL: https://nostarch.com//python-crash-course-3rd-edition\n",
      "\n",
      "Book 7:\n",
      "Title: Python Tools for Scientists\n",
      "Author: Lee Vaughan\n",
      "Number of Pages: 375 pp.\n",
      "Release Date: September 2020\n",
      "URL: https://nostarch.com//python-tools-scientists\n",
      "\n",
      "Book 8:\n",
      "Title: The Art of Clean Code\n",
      "Author: Christian Mayer\n",
      "Number of Pages: 633 pp.\n",
      "Release Date: April 2022\n",
      "URL: https://nostarch.com//art-clean-code\n",
      "\n",
      "Book 9:\n",
      "Title: Python for Data Science\n",
      "Author: Yuli Vasiliev\n",
      "Number of Pages: 469 pp.\n",
      "Release Date: December 2013\n",
      "URL: https://nostarch.com//python-data-science\n",
      "\n",
      "Book 10:\n",
      "Title: The Book of Dash\n",
      "Author: Adam Schroeder, Christian Mayer, and Ann Marie Ward\n",
      "Number of Pages: 639 pp.\n",
      "Release Date: August 2004\n",
      "URL: https://nostarch.com//book-dash\n"
     ]
    }
   ],
   "source": [
    "# THIS IS HOW SOMEONE WHO SAYS THEY WANT TO BE A DEVELOPER DEFINES A PROPER MAIN FUNCTION\n",
    "# AND TO THINK IN CSC 121 I DIDNT EVEN UNDERSTAND THE PURPOSE OF MAIN, LOL:\n",
    "\n",
    "def main():\n",
    "    url = \"catalog/python\"\n",
    "    books = scrape_book_page(url)\n",
    "    books = scrape_book_details(books)\n",
    "\n",
    "    save_to_csv(books)\n",
    "\n",
    "    print(\"Scraping complete! Your spoofed .csv is ready!\")\n",
    "    print('Here is a sample of your first 10 results:')\n",
    "    # Print only the first 10 results\n",
    "    #print(\"\\nFirst 10 Results:\")\n",
    "    display_first_10_results(books)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa4989-b7b1-44b4-8c46-88e3ebed7b28",
   "metadata": {},
   "source": [
    "# CSV Sample Output\n",
    "![CSV Sample Output](CSV-Output-Sample.png)\n",
    "\n",
    "### Notice the diffence?!\n",
    "\n",
    "# Python Books Catalog\r\n",
    "\r\n",
    "![Python Books Catalog](Python-by-No-Starch-Press.jpg)\r\n",
    "\r\n",
    "This catalog contains information about popular Python books available at No Starch Press.\r\n",
    "\r\n",
    "The data was scraped from their website using web scraping techniques and Python libraries such as `requests` and `BeautifulSoup`. \r\n",
    "\r\n",
    "Key features of this project:\r\n",
    "- Scrapes book titles, authors, page counts, and publication dates\r\n",
    "- Generates random page counts and dates when specific information wasn't available\r\n",
    "- Saves the data to a CSV file named `spoofed.csv`\r\n",
    "- Displays the first 10 results in tms of service.\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17bc572-6c1e-43be-88d4-0581509f060c",
   "metadata": {},
   "source": [
    "![Pandas](Pandas.png)\n",
    "\n",
    "# Data Visualization with Pandas\n",
    "\n",
    "## Step 1: Importing and Creating a DataFrame\n",
    "\n",
    "Now that we have successfully created a web scraper that generates a spoofed CSV file every time our program runs, it's time to work on the data visualization part of the code.\n",
    "\n",
    "For the first step, we'll import the spoofed CSV file and use the Pandas library along with its DataFrame and Series functions to create a data frame. A data frame is a structure constructed with rows and columns, similar to the CSV we used, but with more functionality for data visualization.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "### Code Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2c42207c-3115-468e-831c-9c1dde9436b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75eb9b78-c889-4ac5-96a9-896d542b3f80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Number of Pages</th>\n",
       "      <th>Release Date</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Title</td>\n",
       "      <td>Author</td>\n",
       "      <td>Number of Pages</td>\n",
       "      <td>Release Date</td>\n",
       "      <td>URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python for Excel Power Users</td>\n",
       "      <td>Tracy Stephens</td>\n",
       "      <td>749 pp.</td>\n",
       "      <td>February 2021</td>\n",
       "      <td>https://nostarch.com//python-excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Automate the Boring Stuff with Python, 3rd Edi...</td>\n",
       "      <td>Al Sweigart</td>\n",
       "      <td>619 pp.</td>\n",
       "      <td>January 2007</td>\n",
       "      <td>https://nostarch.com//automate-boring-stuff-py...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python Playground, 2nd Edition</td>\n",
       "      <td>Mahesh Venkitachalam</td>\n",
       "      <td>666 pp.</td>\n",
       "      <td>December 2022</td>\n",
       "      <td>https://nostarch.com//python-playground-2nd-ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python for Kids, 2nd Edition</td>\n",
       "      <td>Jason R. Briggs</td>\n",
       "      <td>827 pp.</td>\n",
       "      <td>February 2018</td>\n",
       "      <td>https://nostarch.com//python-kids-2nd-edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dive Into Data Science</td>\n",
       "      <td>Bradford Tuckfield</td>\n",
       "      <td>540 pp.</td>\n",
       "      <td>February 2001</td>\n",
       "      <td>https://nostarch.com//dive-data-science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Python Crash Course, 3rd Edition</td>\n",
       "      <td>Eric Matthes</td>\n",
       "      <td>820 pp.</td>\n",
       "      <td>December 2022</td>\n",
       "      <td>https://nostarch.com//python-crash-course-3rd-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Python Tools for Scientists</td>\n",
       "      <td>Lee Vaughan</td>\n",
       "      <td>518 pp.</td>\n",
       "      <td>December 2012</td>\n",
       "      <td>https://nostarch.com//python-tools-scientists</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Art of Clean Code</td>\n",
       "      <td>Christian Mayer</td>\n",
       "      <td>348 pp.</td>\n",
       "      <td>January 2009</td>\n",
       "      <td>https://nostarch.com//art-clean-code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Python for Data Science</td>\n",
       "      <td>Yuli Vasiliev</td>\n",
       "      <td>332 pp.</td>\n",
       "      <td>February 2013</td>\n",
       "      <td>https://nostarch.com//python-data-science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Book of Dash</td>\n",
       "      <td>Adam Schroeder, Christian Mayer, and Ann Marie...</td>\n",
       "      <td>825 pp.</td>\n",
       "      <td>August 2018</td>\n",
       "      <td>https://nostarch.com//book-dash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                                               Title   \n",
       "1                        Python for Excel Power Users   \n",
       "2   Automate the Boring Stuff with Python, 3rd Edi...   \n",
       "3                      Python Playground, 2nd Edition   \n",
       "4                        Python for Kids, 2nd Edition   \n",
       "5                              Dive Into Data Science   \n",
       "6                    Python Crash Course, 3rd Edition   \n",
       "7                         Python Tools for Scientists   \n",
       "8                               The Art of Clean Code   \n",
       "9                             Python for Data Science   \n",
       "10                                   The Book of Dash   \n",
       "\n",
       "                                               Author  Number of Pages  \\\n",
       "0                                              Author  Number of Pages   \n",
       "1                                      Tracy Stephens          749 pp.   \n",
       "2                                         Al Sweigart          619 pp.   \n",
       "3                                Mahesh Venkitachalam          666 pp.   \n",
       "4                                     Jason R. Briggs          827 pp.   \n",
       "5                                  Bradford Tuckfield          540 pp.   \n",
       "6                                        Eric Matthes          820 pp.   \n",
       "7                                         Lee Vaughan          518 pp.   \n",
       "8                                     Christian Mayer          348 pp.   \n",
       "9                                       Yuli Vasiliev          332 pp.   \n",
       "10  Adam Schroeder, Christian Mayer, and Ann Marie...          825 pp.   \n",
       "\n",
       "     Release Date                                                URL  \n",
       "0    Release Date                                                URL  \n",
       "1   February 2021                 https://nostarch.com//python-excel  \n",
       "2    January 2007  https://nostarch.com//automate-boring-stuff-py...  \n",
       "3   December 2022  https://nostarch.com//python-playground-2nd-ed...  \n",
       "4   February 2018      https://nostarch.com//python-kids-2nd-edition  \n",
       "5   February 2001            https://nostarch.com//dive-data-science  \n",
       "6   December 2022  https://nostarch.com//python-crash-course-3rd-...  \n",
       "7   December 2012      https://nostarch.com//python-tools-scientists  \n",
       "8    January 2009               https://nostarch.com//art-clean-code  \n",
       "9   February 2013          https://nostarch.com//python-data-science  \n",
       "10    August 2018                    https://nostarch.com//book-dash  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = [ 'Title', 'Author','Number of Pages', 'Release Date', 'URL' ]\n",
    "DF_PYTHON_BOOKS = pd.read_csv('python_books.csv', names=cols)\n",
    "DF_PYTHON_BOOKS.head(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18ddae-2004-4b6c-804c-b5de4b65dbd0",
   "metadata": {},
   "source": [
    "![Matplotlib](matplotlib.png)\n",
    "\n",
    "# Data Visualization with Matplotlib\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The key to effective data visualization is conveying information in a format that is much easier to interpret, especially for non-technical audiences. Matplotlib is a powerful tool for data visualization in Python.\n",
    "\n",
    "## About Matplotlib\n",
    "\n",
    "Matplotlib is a multi-platform data visualization library built on NumPy arrays and designed to work with the broader SciPy stack. One of its most important features is its ability to play well with many operating systems and graphics backends.\n",
    "\n",
    "## Application to Programming Language Learning\n",
    "\n",
    "With the data we scraped from the No Starch Press site, we can graphically demonstrate various aspects of programming language learning. Let's consider the case of learning Python!\n",
    "\n",
    "Are you looking to:\n",
    "\n",
    "1. Learn a new programming language (PYTHON!)\n",
    "2. Find a book that's easy to get into and complete in a weekend (around 200 pages)?\n",
    "3. Dive deep into a comprehensive 700-page reference manual for in-depth Python knowledge over several months?\n",
    "\n",
    "## Creating a Visualization\n",
    "\n",
    "Let's use Matplotlib to create a visualization that can help with this decision-making process. First, we need to write some code...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a59547-58d5-4c10-957c-fc5c5bb5fa90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
